# GrokCast - Quick Start Guide

## ğŸš€ You're All Set!

The development server is now running at: **http://localhost:3000**

## âœ… What's Working

- âœ¨ Full Next.js 16 app with TypeScript
- ğŸ¨ Tailwind CSS configured and ready
- ğŸ¥ VideoPlayer with dual-video cross-fading
- ğŸ’¬ ChatInterface for user interaction
- ğŸ›ï¸ StateSoundboard for manual state control
- ğŸ¤– Mock Grok API responses (works without API key)
- ğŸ“¦ Three-tier caching system
- ğŸ”„ State machine with 6 video states

## ğŸ“‚ Project Structure

```
grokcast-demo/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ respond/route.ts         # Main orchestration API
â”‚   â”‚   â””â”€â”€ clips/[sessionId]/[clipId]/route.ts  # Serve cached clips
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ VideoPlayer.tsx          # Dual-video cross-fading
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx        # Chat UI
â”‚   â”‚   â””â”€â”€ StateSoundboard.tsx      # Manual controls
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ grok-client.ts           # Grok API wrapper (with mocks)
â”‚   â”‚   â”œâ”€â”€ clip-manager.ts          # Caching logic
â”‚   â”‚   â””â”€â”€ state-machine.ts         # Video state definitions
â”‚   â””â”€â”€ types/index.ts               # TypeScript types
â””â”€â”€ storage/                         # Runtime clip cache (auto-created)
```

## ğŸ® How to Use

1. **Open the app**: http://localhost:3000
2. **Type a message** in the chat box
3. **Watch the video state change** based on your message
4. **Use the soundboard** to manually trigger states
5. **Experiment** with different messages:
   - "Hello" â†’ triggers smile
   - "Why..." â†’ triggers thinking
   - "Thank you" â†’ triggers nod
   - Any question â†’ thinking then speaking

## ğŸ”§ Next Steps

### Add Real Grok API Integration

1. Get API key from https://x.ai
2. Create `.env.local`:
   ```bash
   GROK_API_KEY=your_actual_api_key_here
   ```
3. Restart the dev server
4. Now it will use real Grok AI!

### Customize the Persona

Edit `app/lib/state-machine.ts` to change:
- Video prompts (appearance, lighting, style)
- State durations
- Allowed transitions
- Add new states

### Pre-generate Core Clips

Once you have the Grok API working:

1. Run a few conversations to generate clips
2. Copy best clips from `storage/[session]` to `public/clips/`
3. Rename to match state names (e.g., `idle_listening.mp4`)
4. These will be used instantly on every load!

## ğŸ› Troubleshooting

**Port 3000 already in use?**
```bash
# Kill the process and restart
npm run dev -- -p 3001
```

**TypeScript errors?**
```bash
# Rebuild
npm run build
```

**Videos not playing?**
- Check browser console for errors
- Try Chrome/Edge (best support)
- Ensure placeholder video URL is accessible

## ğŸ“ Development Tips

### Mock Mode (Current)
- Works without API key
- Uses keyword-based responses
- Uses public sample video
- Perfect for UI development

### Production Mode
- Requires Grok API key
- Generates real AI responses
- Creates custom video clips
- Caches aggressively

## ğŸ¯ Demo Flow

For hackathon demo:

1. **Intro**: "This is compositional video realism..."
2. **Type**: "Hello!" â†’ watch smile reaction
3. **Type**: "Why is the sky blue?" â†’ watch thinking â†’ speaking
4. **Use soundboard**: Show manual state control
5. **Explain**: "Each state is a 1-3s clip, orchestrated by AI"
6. **Show code**: Briefly show state machine config

## ğŸš€ Deploy to Vercel

```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel

# Add environment variable in Vercel dashboard:
# GROK_API_KEY=your_key
```

## ğŸ“Š Performance Notes

Current setup (mock mode):
- First load: < 2s
- State transitions: ~400ms
- Chat response: instant (mock)

With Grok API:
- First generation: 5-15s per clip
- Cached clips: instant
- Chat response: < 1s

## ğŸ¨ Customization Ideas

- Change color scheme in `tailwind.config.ts`
- Add more states (excited, confused, etc.)
- Implement voice input
- Add background audio
- Create multiple personas
- Add WebGL transition effects

---

**Need help?** Check README.md for full documentation.

**Ready to present?** You have a working demo! ğŸ‰
